{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "camw_py8JDgq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "G9t-EyACMRvg"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "108U9ZOFMcDh"
      },
      "outputs": [],
      "source": [
        "# !python -m atari_py.import_roms /content/drive/MyDrive/optimization_colabs/Roms/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "psSsaPDUJDg1"
      },
      "outputs": [],
      "source": [
        "def prepro(I):\n",
        "    # preprocess each frame for learning\n",
        "    # save some memory and computation\n",
        "    # pre-process the image from a 210x160x3 uint8 frame into an (80x80) float array \n",
        "    I = I[35:195,:,:].copy() # crop the top of the image...score image doesn't matter for how to play\n",
        "    I = I[::2,::2,0].copy()\n",
        "    I[I == 144] = 0 # erase background (background type 1)\n",
        "    I[I == 109] = 0 # erase background (background type 2)\n",
        "    I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
        "    return np.array(I.copy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Nn6hDx4YJDg6"
      },
      "outputs": [],
      "source": [
        "def discount_rewards(r):\n",
        "    # take 1D float array of rewards and compute discounted reward\n",
        "    # gym returns a reward with every single frame.  most of those rewards are 0\n",
        "    # sometimes they're 1 or -1 if we win or lose a point in that specific frame\n",
        "    # we want non-0 rewards for every frame. \n",
        "    # so take each frame, figure out if we eventually won the corresponding point or not\n",
        "    # if so make the reward positive, if not negative\n",
        "    # but more recent actions (relative to the frame where the point is awarded) are more \n",
        "    # impactful to the score that frames a long time ago, so discount rewards...\n",
        "    \n",
        "    delt = 0.99 # discount factor\n",
        "    nr = r.shape[0]\n",
        "    # we want to change all those zeros into discounted values of the next reward (this is the value function!)\n",
        "    discounted_r = np.zeros(nr)\n",
        "    \n",
        "    for t in range(nr):\n",
        "        # start at the end\n",
        "        if r[nr-t-1] > 0: # if you won a point in this frame we want a good reward\n",
        "            discounted_r[nr-t-1] = 1 \n",
        "        elif r[nr-t-1] < 0: # if we lost the point we want a bad reward\n",
        "            discounted_r[nr-t-1] = -1\n",
        "        elif t==0: # this is just for error catching...at t==0 r[nr-t-1] should have already been + or -...\n",
        "            discounted_r[nr-t-1] = 0\n",
        "        elif discounted_r[nr-t-1] == 0: # otherwise you want to look at the next reward value and discount it\n",
        "            discounted_r[nr-t-1] = delt*discounted_r[nr-t]\n",
        "    return discounted_r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_mXligTNJDg9"
      },
      "outputs": [],
      "source": [
        "def create_model(height,width,channels):\n",
        "    # we cannot simply have 3 output nodes because we want to put a weight on each node's impact to the objective\n",
        "    # that is different for each data point.  the only way to achieve this is to have 3 output layers, each having 1 node\n",
        "    # the effect is the same, just the way TF/keras handles weights is different\n",
        "    imp = Input(shape=(height,width,channels))\n",
        "    mid = Conv2D(16,(8,8),strides=4,activation='relu')(imp)\n",
        "    mid = Conv2D(32,(4,4),strides=2,activation='relu')(mid)\n",
        "    mid = Flatten()(mid)\n",
        "    mid = Dense(256,activation='relu')(mid)\n",
        "    out0 = Dense(3,activation='softmax')(mid)\n",
        "    model = Model(imp,out0) \n",
        "    \n",
        "    model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-4),loss='sparse_categorical_crossentropy')\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nfkL-PynKDDk"
      },
      "outputs": [],
      "source": [
        "frames_to_net = 4              # how many previous frames will we feed the NN\n",
        "possible_actions = [0,2,3]\n",
        "mod = create_model(80,80,frames_to_net)\n",
        "mod.call = tf.function(mod.call,experimental_relax_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OhWx3oNoJDg-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 80, 80, 4)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 19, 19, 16)        4112      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 8, 8, 32)          8224      \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               524544    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 771       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 537,651\n",
            "Trainable params: 537,651\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "mod.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9zpQoSTJDhE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ncJzdArEJDhG"
      },
      "outputs": [],
      "source": [
        "def play1game(model):\n",
        "    env0 = gym.make(\"Pong-v0\")\n",
        "    pix = env0.reset()\n",
        "    pix = prepro(pix)\n",
        "    frames_this_game = 0\n",
        "    feed = np.zeros((1,80,80,frames_to_net))\n",
        "    feed[0,:,:,0] = pix.copy()\n",
        "    \n",
        "    frame_array = []\n",
        "    action_array = []\n",
        "    reward_array = []\n",
        "    \n",
        "    score = 0\n",
        "    done = False\n",
        "    while not done:\n",
        "        vf = model(feed,training=False).numpy()[0]\n",
        "        action = np.random.choice(3,p=vf)\n",
        "        \n",
        "        action0 = possible_actions[action]\n",
        "        pix_new, reward, done, info = env0.step(action0)\n",
        "        frame_array.append(pix)\n",
        "        action_array.append(action)\n",
        "        reward_array.append(reward)\n",
        "        pix = prepro(pix_new)\n",
        "        frames_this_game += 1\n",
        "\n",
        "        for f in range(1,frames_to_net):\n",
        "            feed[0,:,:,frames_to_net-f] = feed[0,:,:,frames_to_net-f-1].copy()\n",
        "        feed[0,:,:,0] = pix.copy()\n",
        "        score += reward\n",
        "        \n",
        "    return frame_array, action_array, reward_array, score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NNaZNRrRWdYs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.3306613226452906 0.33132932531730125 0.3380093520374082\n"
          ]
        }
      ],
      "source": [
        "frames, actions, rewards, score = play1game(mod)\n",
        "print(np.mean(np.array(actions)==0),np.mean(np.array(actions)==1),np.mean(np.array(actions)==2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "TXFCL6EwJDhI"
      },
      "outputs": [],
      "source": [
        "ngames = 1\n",
        "batches_per_epoch = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yvP9fpTYKiUG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
            "[0, -21.0, 30.745014190673828]\n"
          ]
        }
      ],
      "source": [
        "for game in range(ngames):\n",
        "    start = time.time()\n",
        "    frames, actions, rewards, score = play1game(mod)\n",
        "    rewards = np.array(rewards)\n",
        "    actions = np.array(actions)\n",
        "    nframes = len(frames)\n",
        "    current_frames = np.zeros((nframes,80,80,frames_to_net))\n",
        "    \n",
        "    disc_rewards = discount_rewards(rewards)\n",
        "  \n",
        "    for grab in range(nframes):\n",
        "        for f in range(frames_to_net):\n",
        "            if grab-f > 0:\n",
        "                current_frames[grab,:,:,f] = frames[grab-f].copy()\n",
        "  \n",
        "    mod.fit(current_frames,actions,epochs=1,steps_per_epoch=batches_per_epoch,verbose=0,sample_weight=disc_rewards,use_multiprocessing=True)\n",
        "    # for some reason colab memory was blowing up...this may have fixed it?\n",
        "    del rewards\n",
        "    del actions\n",
        "    del frames\n",
        "    del current_frames\n",
        "    del disc_rewards\n",
        "    stop = time.time()\n",
        "    print([game, score, stop-start])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdYwFUedL8GJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QRQkhtCOS7v"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pvuma3I0X7qW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "topic4-rl3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
