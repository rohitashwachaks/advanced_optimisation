{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "camw_py8JDgq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, Input"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "G9t-EyACMRvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m atari_py.import_roms /content/drive/MyDrive/optimization_colabs/Roms/"
      ],
      "metadata": {
        "id": "108U9ZOFMcDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psSsaPDUJDg1"
      },
      "outputs": [],
      "source": [
        "def prepro(I):\n",
        "    # preprocess each frame for learning\n",
        "    # save some memory and computation\n",
        "    # pre-process the image from a 210x160x3 uint8 frame into an (80x80) float array \n",
        "    I = I[35:195,:,:].copy() # crop the top of the image...score image doesn't matter for how to play\n",
        "    I = I[::2,::2,0].copy()\n",
        "    I[I == 144] = 0 # erase background (background type 1)\n",
        "    I[I == 109] = 0 # erase background (background type 2)\n",
        "    I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
        "    return np.array(I.copy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nn6hDx4YJDg6"
      },
      "outputs": [],
      "source": [
        "def discount_rewards(r):\n",
        "    # take 1D float array of rewards and compute discounted reward\n",
        "    # gym returns a reward with every single frame.  most of those rewards are 0\n",
        "    # sometimes they're 1 or -1 if we win or lose a point in that specific frame\n",
        "    # we want non-0 rewards for every frame. \n",
        "    # so take each frame, figure out if we eventually won the corresponding point or not\n",
        "    # if so make the reward positive, if not negative\n",
        "    # but more recent actions (relative to the frame where the point is awarded) are more \n",
        "    # impactful to the score that frames a long time ago, so discount rewards...\n",
        "    \n",
        "    delt = 0.99 # discount factor\n",
        "    nr = len(r)\n",
        "    # we want to change all those zeros into discounted values of the next reward (this is the value function!)\n",
        "    discounted_r = [0.0]*nr\n",
        "    \n",
        "    for t in range(nr):\n",
        "        # start at the end\n",
        "        if r[nr-t-1] > 0: # if you won a point in this frame we want a good reward\n",
        "            discounted_r[nr-t-1] = 1\n",
        "        elif r[nr-t-1] < 0: # if we lost the point we want a bad reward\n",
        "            discounted_r[nr-t-1] = -1\n",
        "        elif t==0: # this is just for error catching...at t==0 r[nr-t-1] should have already been + or -...\n",
        "            discounted_r[nr-t-1] = 0\n",
        "        elif discounted_r[nr-t-1] == 0: # otherwise you want to look at the next reward value and discount it\n",
        "            discounted_r[nr-t-1] = delt*discounted_r[nr-t]\n",
        "    return discounted_r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mXligTNJDg9"
      },
      "outputs": [],
      "source": [
        "def create_model(height,width,channels):\n",
        "    # we cannot simply have 3 output nodes because we want to put a weight on each node's impact to the objective\n",
        "    # that is different for each data point.  the only way to achieve this is to have 3 output layers, each having 1 node\n",
        "    # the effect is the same, just the way TF/keras handles weights is different\n",
        "    imp = Input(shape=(height,width,channels))\n",
        "    mid = Conv2D(16,(8,8),strides=4,activation='relu')(imp)\n",
        "    mid = Conv2D(32,(4,4),strides=2,activation='relu')(mid)\n",
        "    mid = Flatten()(mid)\n",
        "    mid = Dense(256,activation='relu')(mid)\n",
        "    out0 = Dense(3,activation='softmax')(mid)\n",
        "    model = Model(imp,out0) \n",
        "    \n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-6),loss='sparse_categorical_crossentropy')\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frames_to_net = 4              # how many previous frames will we feed the NN\n",
        "possible_actions = [0,2,3]\n",
        "mod = create_model(80,80,frames_to_net)\n",
        "mod.call = tf.function(mod.call,experimental_relax_shapes=True)"
      ],
      "metadata": {
        "id": "nfkL-PynKDDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhWx3oNoJDg-"
      },
      "outputs": [],
      "source": [
        "mod.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9zpQoSTJDhE"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncJzdArEJDhG"
      },
      "outputs": [],
      "source": [
        "def play1game(model):\n",
        "    env0 = gym.make(\"Pong-v0\")\n",
        "    pix = env0.reset()\n",
        "    pix = prepro(pix)\n",
        "    frames_this_game = 0\n",
        "    feed = np.zeros((1,80,80,frames_to_net))\n",
        "    feed[0,:,:,0] = pix.copy()\n",
        "    \n",
        "    \n",
        "    frame_array = []\n",
        "    action_array = []\n",
        "    reward_array = []\n",
        "    \n",
        "    score = 0\n",
        "    done = False\n",
        "    fcount = 0\n",
        "    while not done:\n",
        "        if fcount == 0:\n",
        "            vf = model(feed,training=False).numpy()[0]\n",
        "            action = np.random.choice(3,p=vf)\n",
        "            fcount += 1\n",
        "        elif fcount == 3:\n",
        "            fcount = 0\n",
        "        else:\n",
        "            fcount += 1\n",
        "\n",
        "        \n",
        "        action0 = possible_actions[action]\n",
        "        pix_new, reward, done, info = env0.step(action0)\n",
        "        frame_array.append(pix)\n",
        "        action_array.append(action)\n",
        "        reward_array.append(reward)\n",
        "        pix = prepro(pix_new)\n",
        "        frames_this_game += 1\n",
        "\n",
        "        for f in range(1,frames_to_net):\n",
        "            feed[0,:,:,frames_to_net-f] = feed[0,:,:,frames_to_net-f-1].copy()\n",
        "        feed[0,:,:,0] = pix.copy()\n",
        "        score += reward\n",
        "        \n",
        "    return frame_array, action_array, reward_array, score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mod = create_model(80,80,frames_to_net)\n",
        "mod.call = tf.function(mod.call,experimental_relax_shapes=True)"
      ],
      "metadata": {
        "id": "NNaZNRrRWdYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6ydYLroudLZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXFCL6EwJDhI"
      },
      "outputs": [],
      "source": [
        "ngames = 10000\n",
        "nbatch = 10\n",
        "buffn = 200000\n",
        "warmupgames = 50\n",
        "len_buff = 0\n",
        "buffer = {'frames':[],'actions':[],'rewards':[]}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for game in range(ngames):\n",
        "    start = time.time()\n",
        "    frames, actions, rewards, score = play1game(mod)\n",
        "    rewards = discount_rewards(rewards.copy())\n",
        "    buffer['frames'] += frames.copy()\n",
        "    buffer['actions'] += actions.copy()\n",
        "    buffer['rewards'] += rewards.copy()\n",
        "    len_buff += len(actions)\n",
        "    if len_buff > buffn:\n",
        "        excess = len_buff - buffn\n",
        "        buffer['frames'] = buffer['frames'][excess:].copy()\n",
        "        buffer['actions'] = buffer['actions'][excess:].copy()\n",
        "        buffer['rewards'] = buffer['rewards'][excess:].copy()\n",
        "        len_buff = len(buffer['actions'])\n",
        "    rewards = np.array(rewards)\n",
        "    actions = np.array(actions)\n",
        "    nframes = len(frames)\n",
        "    current_frames = np.zeros((nframes,80,80,frames_to_net))\n",
        "    \n",
        "    \n",
        "\n",
        "    if game >= warmupgames:\n",
        "        prob = np.ones(len_buff)\n",
        "        prob[np.array(buffer['rewards']) > 0] = 5.0\n",
        "        prob /= np.sum(prob)\n",
        "        which_choose = np.random.choice(len_buff,size=nframes,replace=False,p=prob)\n",
        "    \n",
        "        for grab in range(nframes):\n",
        "            rewards[grab] = buffer['rewards'][which_choose[grab]]\n",
        "            actions[grab] = buffer['actions'][which_choose[grab]]\n",
        "            for f in range(frames_to_net):\n",
        "                if grab-f > 0:\n",
        "                    current_frames[grab,:,:,f] = buffer['frames'][which_choose[grab]-f].copy()\n",
        "    \n",
        "        mod.fit(current_frames,actions,epochs=1,steps_per_epoch=nbatch,verbose=0,sample_weight=rewards,use_multiprocessing=True)\n",
        "    stop = time.time()\n",
        "    print(game, score, stop-start,len_buff)"
      ],
      "metadata": {
        "id": "yvP9fpTYKiUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BdYwFUedL8GJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DNNwPOPsdsNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2hTTcuFQceiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "V74hFb18cebI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0QRQkhtCOS7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "t1U_WMIJhgi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UYLe4F2FxTn-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "topic4-rl4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}